{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Bootstrap_Random_Forest_instructions.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"AjzGopb_YcKR"},"source":["# Application of Bootstrap samples in Random Forest"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"zZSCtDI6YcKT","colab":{}},"source":["import numpy as np\n","from sklearn.datasets import load_boston\n","from sklearn.metrics import mean_squared_error"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"h2Y1Z1DoYcKZ"},"source":[" <li> Load the boston house dataset </li>"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"wBWRNKCDYcKb","colab":{}},"source":["boston = load_boston()\n","x=boston.data #independent variables\n","y=boston.target #target variable"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DTbK20-mWYHU","colab_type":"code","outputId":"b473b251-a104-44df-f6c3-3427184c9042","colab":{}},"source":["x.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(506, 13)"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"JJ_FwP7xYcKg"},"source":["### Task: 1\n","<font color='red'><b>Step 1 Creating samples: </b></font> Randomly create 30 samples from the whole boston data points.\n","<ol>\n","<li>Creating each sample: Consider any random 303(60% of 506) data points from whole data set and then replicate any 203 points from the sampled points</li>\n","<li>Ex: For better understanding of this procedure lets check this examples, assume we have 10 data points [1,2,3,4,5,6,7,8,9,10], first we take 6 data points randomly consider we have selected [4, 5, 7, 8, 9, 3] now we will replciate 4 points from [4, 5, 7, 8, 9, 3], consder they are [5, 8, 3,7] so our final sample will be [4, 5, 7, 8, 9, 3, 5, 8, 3,7]</li>\n","<li> we create 30 samples like this </li>\n","<li> Note that as a part of the Bagging when you are taking the random samples make sure each of the sample will have                different set of columns</li>\n","<li> Ex: assume we have 10 columns for the first sample we will select [3, 4, 5, 9, 1, 2] and for the second sample [7, 9, 1, 4, 5, 6, 2] and so on...</li>\n","<li> Make sure each sample will have atleast 3 feautres/columns/attributes</li>\n","</ol>\n","\n","<font color='red'><b>Step 2 Building High Variance Models on each of the sample and finding train MSE value:</b></font> Build a DecisionTreeRegressor on each of the sample.\n","<ol><li>Build a regression trees on each of 30 samples.</li>\n","<li>computed the predicted values of each data point(506 data points) in your corpus.</li>\n","<li> predicted house price of $i^{th}$ data point $y^{i}_{pred} =  \\frac{1}{30}\\sum_{k=1}^{30}(\\text{predicted value of } x^{i} \\text{ with } k^{th} \\text{ model})$.</li>\n","<li>Now calculate the $MSE =  \\frac{1}{506}\\sum_{i=1}^{506}(y^{i} - y^{i}_{pred})^{2}$.</li>\n","</ol>\n","\n","<font color='red'><b>Step 3 Calculating the OOB score :</b></font>\n","<ol>\n","<li>Computed the predicted values of each data point(506 data points) in your corpus.</li>\n","<li>Predicted house price of $i^{th}$ data point $y^{i}_{pred} =  \\frac{1}{k}\\sum_{\\text{k= model which was buit on samples not included } x^{i}}(\\text{predicted value of } x^{i} \\text{ with } k^{th} \\text{ model})$.</li>\n","<li>Now calculate the $OOB Score =  \\frac{1}{506}\\sum_{i=1}^{506}(y^{i} - y^{i}_{pred})^{2}$.</li>\n","</ol>\n","\n","### Task: 2\n","<pre>\n","<font color='red'><b>Computing CI of OOB Score and Train MSE</b></font>\n","<ol>\n","<li> Repeat Task 1 for 35 times, and for each iteration store the Train MSE and OOB score </li>\n","<li> After this we will have 35 Train MSE values and 35 OOB scores </li>\n","<li> using these 35 values (assume like a sample) find the confidence intravels of MSE and OOB Score </li>\n","<li> you need to report CI of MSE and CI of OOB Score </li>\n","<li> Note: Refer the Central_Limit_theorem.ipynb to check how to find the confidence intravel</li>\n","</ol>\n","</pre>\n","### Task: 3\n","<pre>\n","<font color='red'><b>Given a single query point predict the price of house.</b></font>\n","\n","<li>Consider xq= [0.18,20.0,5.00,0.0,0.421,5.60,72.2,7.95,7.0,30.0,19.1,372.13,18.60] Predict the house price for this point as mentioned in the step 2 of Task 1. </li>\n","</pre>"]}]}